# -*- coding: utf-8 -*-
"""Yulu_Analysis_by_Pritam.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qjol83BIf_tJdQT2wRWTdmStFnAg9KZA
"""

# Importing the required libraries
# Pandas and Numpy libraries will be used for data manipulations, Matplotlib and Seaborn will be used for data visualizations which will be required for Analysis.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Let's look at the data
df = pd.read_csv('/content/bike_sharing.txt')
df.head()

df.shape   # There are 10886 rows of data with 12 features\columns

df.info()  # Let's look at the datatype for each column and look for missing values

df.isna().sum()  # There seems to be no missing values present so there is no need to handle null\missing values

df['datetime'] = pd.to_datetime(df['datetime'])
df['datetime'].dtype

df.info()   # We can change the datatype for 'datetime' column to datetime datatype from object

df.describe() # Statistical analysis for the available data

"""**Insights**
From the above info we can observe that:

Season:
The data covers all four seasons, with a mean value of approximately 2.51.
The minimum value is 1 (spring), and the maximum value is 4 (winter).
The most frequent season seems to be fall or winter, as the mean is closer to 3.


Holiday:
On average, only around 2.86% of the days are holidays.
The majority of the days are non-holidays.

Working Day:
Around 68.09% of the days are working days.
The dataset predominantly consists of working days.

Weather:
The weather variable ranges from 1 to 4, representing different weather conditions.
On average, the weather condition is close to 'Clear, Few clouds, partly cloudy'.

Temperature (temp) and Feeling Temperature (atemp):
The average temperature is approximately 20.23°C, with a standard deviation of around 7.79°C.
The feeling temperature (atemp).
The average temperature is approximately 23.65°C, with a standard deviation of around 8.47°C.
There seems to be a slight difference between the mean temperature and the mean feeling temperature.

Humidity and Windspeed:
The average humidity is approximately 61.89%, with a standard deviation of around 19.25%.
The windspeed ranges from 0 to 56.9969, with an average of 12.80.

Casual Users, Registered Users, and Total Rental Counts:
The average count of casual users is approximately 36.02, with a standard deviation of around 49.96.
The average count of registered users is approximately 155.55, significantly higher than casual users.
The total rental counts (sum of casual and registered users) range from 1 to 977, with an average of approximately 191.57.

These insights provide a preliminary understanding of the dataset and set the stage for further analysis and hypothesis testing to uncover relationships.
"""

df['season'].unique()  # There are four different seasons

df['weather'].unique()  # There are four weather conditions

df['holiday'].unique()

df['holiday'].value_counts()  # we can name 0 as a 'No' and 1 as a 'Yes', since number of holidays seem to be always less in number we can name them as mentioned
                              # for better understanding

df['holiday'] = df['holiday'].apply(lambda x: 'Yes' if x == 1 else 'No')
df['holiday'].head()

df['workingday'].unique()

df['workingday'].value_counts() # If day is neither weekend nor holiday is 1 or 'Yes', otherwise is 0 or 'No'.

df['workingday'] = df['workingday'].replace({1 : 'Yes', 0 : 'No'})
df['workingday'].head()

# Similarly let's replace numbers for season with their appropriate season names
df['season'] = df['season'].replace({1: 'spring', 2: 'summer', 3: 'fall', 4: 'winter'})
df['season'].unique()

# Similarly let's replace numbers for weather with their appropriate short weather names
df['weather'] = df['weather'].replace({1: 'clear', 2: 'mist', 3: 'light snow', 4: 'heavy rain'})
df['weather'].unique()

df['weather'].tail()

df.head()

"""### Univariate Analysis for Continuous variables"""

plt.figure(figsize=(12, 4))
plt.subplot(1, 3, 1)
sns.histplot(df['temp'], kde=True, bins=20, color='skyblue')
plt.title('Temperature Distribution')

plt.subplot(1, 3, 2)
sns.histplot(df['humidity'], kde=True, bins=20, color='salmon')
plt.title('Humidity Distribution')

plt.subplot(1, 3, 3)
sns.histplot(df['windspeed'], kde=True, bins=20, color='green')
plt.title('Windspeed Distribution')

plt.show()

"""**Insights**
1. Temperature Distribution:
The temperature distribution appears to be approximately normal with a peak around the average temperature.
There are no significant outliers.
The majority of the temperature readings fall within a certain range, indicating consistency in temperature over time.

2. Humidity Distribution:
The distribution of humidity seems slightly left-skewed, indicating a higher frequency of higher humidity levels.
There are no apparent outliers or just single/couple of them.
Humidity levels mostly range between 40% and 80%, which is typical for many regions.

3. Windspeed Distribution:
Windspeed distribution is right-skewed, with a peak at lower windspeed values.
There are some outliers at higher windspeeds, suggesting occasional windy days.
The majority of the data points fall within a relatively narrow range of windspeeds.

"""

sns.boxplot(data=df, y='windspeed')
plt.title('Boxplot for Windspeed to detect presence of Outliers')
plt.show()

"""**Insights**: From the above boxplot we can see that the there are some outliers that exist for windspeed and all the outliers lie above the upper bound which is evidently above a wind speed of 30. The max wind speed that has occurred has been around 57.

Recommendation: These conditions might prove to be risky for riders and might be prone to accidents. Yulu can think of providing information on wind conditions to users through the app and recommend alternative routes or sheltered paths during windy days.

"""

upper_whisker =  np.percentile(df['windspeed'], 75) + 1.5 * (np.percentile(df['windspeed'], 75) - np.percentile(df['windspeed'], 25))
upper_whisker

df['windspeed'].count(), (df['windspeed'] > upper_whisker).sum() # There are 227 outliers

# Let's handle the outliers in windspeed with a method known as winsorization where we replace the extreme values with less extreme values.
# We can replace outliers with a predefined percentile value (e.g., the 95th percentile) to minimize their impact on our analysis.
percentile_95 = np.percentile(df['windspeed'], 95)

# Replace outliers with the 95th percentile value
df['windspeed'] =  np.where(df['windspeed'] > upper_whisker, percentile_95, df['windspeed'])

df['windspeed'].count(), (df['windspeed'] > upper_whisker).sum()

"""### Univariate analysis for Categorical variables"""

plt.figure(figsize = (16,8))
plt.subplot(2, 3, 4)
sns.countplot(x='season', data=df, hue='season')
plt.title('Season Counts')

plt.subplot(2, 3, 5)
sns.countplot(x='holiday', data=df, hue='holiday')
plt.title('Holiday Counts')

plt.subplot(2, 3, 6)
sns.countplot(x='workingday', data=df, hue='workingday')
plt.title('Working Day Counts')

plt.show()

"""**Insights**
The number of season counts in the dataset seems to be almost same with the spring season counts slightly lesser than the other seasons.
Holiday counts as usual remains to be lesser than non holiday counts which makes it obvious for Working days to be more than the number of Non Working days as it is also evident for the fact that every week has days considered as working other than the weekends.
"""

df.head()

"""### Bivariate Analysis

"""

# Relationship between workday and count
plt.figure(figsize = (16,4))
plt.subplot(1,3,1)
sns.barplot(x='workingday', y='count', data=df, hue='workingday')
plt.title('Average Count by Working Day')
plt.xlabel('Working Day')
plt.ylabel('Average Count')

# Relationship between season and count
plt.subplot(1,3,2)
sns.barplot(x='season', y='count', data=df, hue='season')
plt.title('Average Count by Season')
plt.xlabel('Season')
plt.ylabel('Average Count')

# Relationship between weather and count
plt.subplot(1,3,3)
sns.barplot(x='weather', y='count', data=df, hue='weather')
plt.title('Average Count by Weather')
plt.xlabel('Weather')
plt.ylabel('Average Count')

plt.show()

"""**Insights**

Effect of Working Days: The barplot shows that rental counts are generally higher on working days compared to non-working days. Yulu may need to focus more on providing efficient services during weekdays to cater to commuter demand.

Seasonal Demand Variations: Rental counts vary across different seasons, with potentially higher demand during certain seasons i.e during fall and summer seasons. Yulu can adjust their operations and marketing strategies accordingly to capitalize on peak seasons.

Impact of Weather: Weather conditions appear to influence rental demand, with higher counts during favorable weather conditions i.e during clear weather conditions. Yulu can prepare for fluctuations in demand by adjusting their fleet size and service offerings based on weather forecasts.

Recommendations:
Weekday Promotions: Implement targeted promotions or discounts during weekdays to encourage more rentals, especially among commuters.

Seasonal Campaigns: Develop seasonal marketing campaigns and offers to attract more users during peak seasons and maximize revenue.

Weather-based Services: Offer weather-specific services or incentives, such as discounts during rainy days or promotions for riding on sunny days, to encourage usage regardless of weather conditions.
"""

df.head()

plt.figure(figsize = (12, 6))
sns.scatterplot(data=df, x='humidity', y='count', hue='season')
plt.title('Distribution of Count of Rental Bikes based on Humidity')
plt.xlabel('Humidity')
plt.ylabel('Rental Bikes Count')

plt.show()

"""**Insights**
From the above graph we can observe that the most number of bikes are rented during the fall season representing in green followed by summer and winter where the humidity for riders seems to be between 30 to 70. The least number of bikes to be rented are observed in the spring season where the humidity gradually drops down.

Recommendation:
Recognizing the lower demand during the spring season, Yulu can develop targeted strategies to stimulate rental activity during this period. This could include offering spring-specific promotions, introducing new features or services.
"""

df.info()

# Convert categorical variables to 'category' datatype
df[['season', 'holiday', 'workingday', 'weather']] = df[['season', 'holiday', 'workingday', 'weather']].astype('category')

df.info()

df.isnull().sum()   # Missing values check, no missing values after handling outliers as we have taken care of it

df.head()

plt.figure(figsize = (14, 4))
sns.lineplot(data=df, x='weather', y='temp', color='blue', label='Temperature')
sns.lineplot(data=df, x='weather', y='windspeed', color='red', label='Windspeed')
plt.xlabel('Weather conditions')
plt.ylabel('Temperature in Celsius')
plt.show()

df['temp'].mean(), df['windspeed'].mean()

"""**Insights**:
In particular to weather conditions, from the above lineplot we can observe that the temperature and windspeed drops darastically during heavy rain in comparison with the average temp (20.23°C) and average windspeed of 12.62, which also seems to be unfavourable conditions for riders to ride, hence might also lead to dropping of rented bikes.

Recommendation:
Offer flexible rental policies during adverse weather conditions, such as allowing users to extend rental durations without additional charges or providing refunds or credits for unused rental time. This can help the inconvenience caused to users due to unexpected weather changes and enhance customer satisfaction.

Consider offering weather protection gear such as raincoats, umbrellas, or windproof jackets at Yulu zones during rainy or windy days. Providing access to such gear can encourage users to continue riding despite unfavorable weather conditions and ensure a comfortable and safe riding experience.

### 2-Sample T-Test for the hypothesis "Working Day has no effect on the number of electric cycles rented" versus "Working Day has an effect on the number of electric cycles rented"
"""

df.head()

#Let's segregate the data first
workingday = df.loc[df['workingday'] == 'Yes', 'count']
non_workingday = df.loc[df['workingday'] == 'No', 'count']

len(workingday)

# Data should follow a normal distribution for a 2 Sample T-Test
# Let's check for normality of workingday data using Shapiro-Wilk test
from scipy.stats import shapiro

np.random.seed(42)
workingday_subset = workingday.sample(100)

test_stat, p_value = shapiro(workingday_subset)
print(f"P-Value: {p_value}")

if p_value < 0.05:
    print("Reject H0")
    print("Data is not Gaussian")
else:
    print("Fail to reject H0")
    print("Data is Gaussian")

# Let's check for normality of non workingday data using Shapiro-Wilk test
np.random.seed(42)
non_workingday_subset = non_workingday.sample(100)

test_stat, p_value = shapiro(non_workingday_subset)
print(f"P-Value: {p_value}")

if p_value < 0.05:
    print("Reject H0")
    print("Data is not Gaussian")
else:
    print("Fail to reject H0")
    print("Data is Gaussian")

"""Null Hypothesis: Working Day has no effect on the number of electric cycles rented.

Alternate Hypothesis: Working Day has an effect on the number of electric cycles rented.
"""

# Though the assumptions for normal distributions fail we'll still continue to perform the T-Test as suggested in the business case
import scipy.stats as stats

# Let's follow the hypothesis framework
# step 1: Setting up Null and Alternate hypothesis as shown above

# step 2: Choosing the test statistic and distribution, in this case it will be a 2 Sample T-Test
# step 3: Choosing a left tailed, right tailed or two tailed: in this case it will be a two-tailed test

# step 4: Compute the p-value by perfoorming 2-Sample T-Test
t_statistic, p_value = stats.ttest_ind(workingday, non_workingday)

# Set significance level (alpha)
alpha = 0.05

# Results
print("2-Sample T-Test Results:")
print("T-Statistic:", t_statistic)
print("P-Value:", p_value)

# step 5: Compare the p-value with alpha and make decisions
if p_value < alpha:
    print("Reject the null hypothesis. Working Day has an effect on the number of electric cycles rented.")
else:
    print("Fail to reject the null hypothesis. Working Day has no effect on the number of electric cycles rented.")

"""**Insights**:
This implies that the day of the week (working day or non-working day) does not have a substantial impact on the demand for shared electric cycles.

**Recommendations**:
 Instead of focusing solely on working days, Yulu can develop targeted marketing strategies to attract riders on both working and non-working days. This could include promoting leisure rides, weekend getaways, or recreational activities to encourage usage during non-working days.
  Yulu can offer discounts or special packages for rentals on weekends or holidays to attract more users during these periods.

### ANOVA (Analysis of Variance) for the hypothesis "The number of cycles rented is similar across different weather conditions and seasons" versus "The number of cycles rented differs across different weather conditions and seasons,"

One Way ANOVA for the number of cycles rented across different weather conditions

Null Hypothesis: The number of cycles rented is similar across different weather conditions.

Alternate Hypothesis: The number of cycles rented differs across different weather conditions.
"""

df['weather'].unique()

df.loc[df['weather'] == 'heavy_rain', 'count']  # No data for weather 'heavy rain' so we can exclude this weather condition while computing anova

# Let's segregate the remaining data
clear_data = df.loc[df['weather'] == 'clear', 'count']
mist_data = df.loc[df['weather'] == 'mist', 'count']
light_snow_data = df.loc[df['weather'] == 'light snow', 'count']

# For One Way ANOVA test data should be normally distributed and there should be equal variance in different groups
# Let's check for the normality of clear_data using a qqplot
from statsmodels.graphics.gofplots import qqplot

qqplot(clear_data, line='s')
plt.show()

# Normality of mist_data
qqplot(mist_data, line='s')
plt.show()

# Normality of light_snow_data
qqplot(light_snow_data, line='s')
plt.show()

# Now we'll check for equal variance using levene's test
from scipy.stats import levene

levene_stat, p_value = levene(clear_data, mist_data, light_snow_data)
print(f"P-value: {p_value}")

if p_value < 0.05:
  print("Variances are not equal")
else:
  print("Variances are equal")

from scipy.stats import f_oneway

# Let's follow the hypothesis framework
# step 1: Setting up Null and Alternate hypothesis as shown above

# step 2: Choosing the test statistic and distribution, in this case it will be one way ANOVA
# step 3: Choosing a left tailed, right tailed or two tailed: in this case it will be a two-tailed test

# Perform ANOVA for each combination of weather condition
f_stats, p_value = f_oneway(clear_data, mist_data, light_snow_data)

# Results
print("test statistic:",f_stats)
print("p_value:",p_value)

# Set significance level (alpha)
alpha = 0.05

# step 5: Compare the p-value with alpha and make decisions
if p_value < alpha:
    print("Reject the null hypothesis. The number of cycles rented differs across different weather conditions.")
else:
    print("Fail to reject the null hypothesis. The number of cycles rented is similar across different weather conditions.")

"""**Insights**:
The rejection of the null hypothesis indicates that the number of cycles rented varies significantly across different weather conditions. This suggests that weather conditions play a significant role in influencing the demand for shared electric cycles.

**Recommendations**:
Yulu can introduce dynamic pricing models that adjust rental rates based on weather conditions. For example, Yulu can offer discounted rates or promotional offers during adverse weather conditions to incentivize ridership and encourage users to choose shared electric cycles as a convenient and weather-resilient mode of transportation.

One Way ANOVA for the number of cycles rented across different seasons

Null Hypothesis: The number of cycles rented is similar across different seasons.

Alternate Hypothesis: The number of cycles rented differs across different seasons.
"""

df['season'].unique()

# Let's segregate the data for seasons and check normality and variance test
spring_data = df.loc[df['season'] == 'spring', 'count']
summer_data = df.loc[df['season'] == 'summer', 'count']
fall_data = df.loc[df['season'] == 'fall', 'count']
winter_data = df.loc[df['season'] == 'winter', 'count']

# Shapiro normality test for spring data
test_stat, p_value = shapiro(spring_data)
print(f"P-Value: {p_value}")

if p_value < 0.05:
  print("Data is not Gaussian for spring_data")
else:
  print("Data is Gaussian for spring_data")

# Shapiro normality test for summer data
test_stat, p_value = shapiro(summer_data)
print(f"P-Value: {p_value}")

if p_value < 0.05:
  print("Data is not Gaussian for summer_data")
else:
  print("Data is Gaussian for summer_data")

# Shapiro normality test for fall data
test_stat, p_value = shapiro(fall_data)
print(f"P-Value: {p_value}")

if p_value < 0.05:
  print("Data is not Gaussian for fall_data")
else:
  print("Data is Gaussian for fall_data")

# Shapiro normality test for winter data
test_stat, p_value = shapiro(winter_data)
print(f"P-Value: {p_value}")

if p_value < 0.05:
  print("Data is not Gaussian for winter_data")
else:
  print("Data is Gaussian for winter_data")

levene_stat, p_value = levene(spring_data, summer_data, fall_data, winter_data)
print(f"P-value: {p_value}")

if p_value < 0.05:
  print("Variances are not equal")
else:
  print("Variances are equal")

# Although the normality and equal variance tests fail for all types season data, we'll still continue to perform the ANOVA test as suggested in the Business Case

# Let's follow the hypothesis framework
# step 1: Setting up Null and Alternate hypothesis as shown above

# step 2: Choosing the test statistic and distribution, in this case it will be one way ANOVA
# step 3: Choosing a left tailed, right tailed or two tailed: in this case it will be a two-tailed test

# Perform ANOVA for each combination of weather condition
f_stats, p_value = f_oneway(spring_data, summer_data, fall_data, winter_data)

# Results
print("test statistic:",f_stats)
print("p_value:",p_value)

# Set significance level (alpha)
alpha = 0.05

# step 5: Compare the p-value with alpha and make decisions
if p_value < alpha:
    print("Reject the null hypothesis. The number of cycles rented differs across different seasons.")
else:
    print("Fail to reject the null hypothesis. The number of cycles rented is similar across different seasons.")

"""**Insights**:
The rejection of the null hypothesis indicates that the number of cycles rented varies significantly across different seasons. This suggests that seasonal factors have a notable impact on the demand for shared electric cycles, with varying usage patterns observed throughout the year.

**Recommendations**:
 Yulu can prioritize maintenance and upkeep activities based on seasonal trends and usage patterns. For instance, ahead of peak cycling seasons, Yulu can conduct thorough inspections and maintenance checks on its electric cycles to ensure optimal performance and safety. Additionally, seasonal weather variations, such as temperature extremes can impact the longevity and durability of fleet components, warranting specific maintenance protocols to each season canl help Yulu make a decent revenue during extreme seasonal or weather conditions.

### Chi-square test to check if Weather is dependent on the Season

Null Hypothesis: There is no significant evidence that weather is dependent on the season.

Alternate Hypothesis: There is evidence that weather is dependent on the season.
"""

from scipy.stats import chi2_contingency

# Let's follow the hypothesis framework
# step 1: Setting up Null and Alternate hypothesis as shown above

# step 2: Choosing the test statistic and distribution, in this case it will be a ANOVA
# step 3: Choosing a left tailed, right tailed or two tailed: in this case it will be a two-tailed test

# Create a contingency table of weather and season
contingency_table = pd.crosstab(df['weather'], df['season'])
contingency_table

# step 4: Compute the p-value by performing chi2_contingency test
chi2, p_value, _, _ = chi2_contingency(contingency_table)

# Print results
print("Chi-square Test Results:")
print("Chi-square Statistic:", chi2)
print("p-value:", p_value)

# Set significance level (alpha)
alpha = 0.05

# step 5: Compare the p-value with alpha and make the decisions
if p_value < alpha:
    print("Reject the null hypothesis.")
    print("There is evidence that weather is dependent on the season.")
else:
    print("Fail to reject the null hypothesis.")
    print("There is no significant evidence that weather is dependent on the season.")

"""**Insights**:
 This implies that the distribution of weather conditions varies significantly across different seasons.

 **Recommendations**:
  Yulu can provide services and operations to accommodate seasonal variations in weather conditions. For instance, during monsoon seasons, when heavy rains are prevalent, Yulu can prioritize maintenance and ensure the availability of waterproofing solutions for its electric cycles. Additionally, Yulu can focus on promoting indoor or sheltered pick-up and drop-off locations to mitigate the impact of adverse weather conditions on riders.
  
   Yulu can implement weather-based marketing strategies to optimize rider engagement and usage. For example, during pleasant weather conditions, such as spring and fall, Yulu can launch promotional campaigns to encourage outdoor activities and leisure rides.
"""

!jupyter nbconvert --to html /content/Yulu_Analysis_by_Pritam.ipynb